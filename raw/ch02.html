<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="utf-8">
  <title>Chapter 2: Building Secure and Reliable Systems</title>
  <link rel="stylesheet" type="text/css" href="theme/html/html.css">
</head>
<body data-type="book">
<h2 class="section-subtitle">Chapter 2</h2>
<section xmlns="http://www.w3.org/1999/xhtml" data-type="chapter" id="understanding_adversaries">
<h1>Understanding Adversaries</h1>

<p class="byline">By Heather Adkins and David Huska</p>
<p class="byline cont">with Jen Barnason‎</p>

<p><a contenteditable="false" data-primary="adversaries, understanding" data-type="indexterm" id="ch02.html0">&nbsp;</a>In <a contenteditable="false" data-primary="Stoll, Clifford" data-type="indexterm" id="ch02.html_ix1">&nbsp;</a>August 1986, Clifford Stoll, a systems administrator at Lawrence Livermore Laboratory, stumbled upon a seemingly benign accounting error that led to a 10-month search for someone stealing government secrets from the United States.<sup><a data-type="noteref" id="ch02fn1-marker" href="#ch02fn1">1</a></sup> Largely considered to be the first public example of its kind, Stoll spearheaded an investigation that laid bare the specific tactics, techniques, and procedures (TTPs) the adversary used to achieve their goals. Through careful study, the investigation team was able to construct a picture of how the attacker targeted and siphoned data out of protected systems. Many system designers have incorporated lessons that arose from Stoll’s seminal article describing the team’s efforts, “Stalking the Wily Hacker.”</p>
<p>In March 2012, Google responded to an unusual power outage at one of its Belgian datacenters that ultimately led to local data corruption. Investigation revealed that a cat had damaged a nearby external power supply, triggering a series of cascading failures in the building’s power systems. By studying how complex systems fail in similar ways, Google has been able to adopt resilient design practices when suspending, burying, and submerging cables around the world.</p>
<p>Understanding a system’s adversaries is critical to building resilience and survivability for a wide variety of catastrophes. In the reliability context, adversaries usually operate with benign intent and take abstract form. They might exist as routine <span class="keep-together">hardware</span> failures or cases of overwhelming user interest (so-called "success disasters"). They could also be configuration changes that cause systems to behave in unexpected ways, or fishing vessels that accidentally sever undersea fiber-optic cables. By contrast, adversaries in the security context are human; their actions are calculated to affect the target system in an undesirable way. Despite these contrasting intents and methods, studying reliability and security adversaries is important for understanding how to design and implement resilient systems. Without this knowledge, anticipating the actions of a Wily Hacker or a Curious Cat would be quite <span class="keep-together">challenging</span>.</p>
<p>In this chapter, we deep dive on security adversaries to help specialists in diverse fields develop an adversarial mindset. It may be tempting to think of security adversaries through the lens of popular stereotypes: attackers in dark basements with clever nicknames and potentially shady behaviors. While such colorful characters certainly exist, anyone with time, knowledge, or money can undermine the security of a system. For a small fee, anyone can purchase software that enables them to take over a computer or mobile phone to which they have physical access. Governments routinely buy or build software to compromise the systems of their targets. Researchers often probe the safety mechanisms of systems to understand how they work. Therefore, we encourage you to maintain an objective perspective about who is attacking a system.</p>
<p>No two attacks—or attackers—are the same. We recommend taking a look at <a data-type="xref" href='ch21.html#twoone_building_a_culture_of_security_a'>Chapter 21</a> for a discussion of the cultural aspects of dealing with adversaries. Predicting future security catastrophes is mostly a guessing game, even for knowledgeable security experts. In the following sections, we present three frameworks to understand attackers that we’ve found helpful over the years, exploring the potential motives of people attacking systems, some common attacker profiles, and how to think about attackers’ methods. We also provide illustrative (and hopefully entertaining) examples within the three frameworks.</p>
<section data-type="sect1" id="attacker_motivations">
<h1>Attacker Motivations</h1>
<p><a contenteditable="false" data-primary="adversaries, understanding" data-secondary="attacker motivations" data-type="indexterm" id="ch02.html_ix2">&nbsp;</a><a contenteditable="false" data-primary="motivations, of attacker" data-type="indexterm" id="ch02.html_ix3">&nbsp;</a>Security adversaries are first and foremost human (at least for the time being). Therefore, we can consider the purpose of attacks through the eyes of the people who carry them out. Doing so may better equip us to understand how we should respond, both proactively (during system design) and reactively (during incidents). Consider the following attack motivations:</p>
<dl>
<dt>Fun</dt>
<dd>To undermine the security of a system for the sheer joy of knowing it can be done.</dd>
<dt>Fame</dt>
<dd>To gain notoriety for showing off technical skills.</dd>
<dt>Activism</dt>
<dd>To make a point or broadcast a message—typically, a political viewpoint— widely.</dd>
<dt>Financial gain</dt>
<dd>To make money.</dd>
<dt>Coercion</dt>
<dd>To get a victim to knowingly do something they don’t want to do.</dd>
<dt>Manipulation</dt>
<dd>To create an intended outcome or change behavior—for example, by publishing false data (misinformation).</dd>
<dt>Espionage</dt>
<dd>To gain information that might be valuable (spying, including industrial espionage). These attacks are often performed by intelligence agencies.</dd>
<dt>Destruction</dt>
<dd>To sabotage a system, destroy its data, or just take it offline.</dd>
</dl>
<p>An attacker might be a financially motivated vulnerability researcher, government espionage agent, and criminal actor all at the same time! <a contenteditable="false" data-primary="North Korea" data-type="indexterm" id="ch02.html_ix4">&nbsp;</a><a contenteditable="false" data-primary="Park Jin Hyok" data-type="indexterm" id="ch02.html_ix5">&nbsp;</a><a contenteditable="false" data-primary="Sony Pictures" data-type="indexterm" id="ch02.html_ix6">&nbsp;</a><a contenteditable="false" data-primary="WannaCry Ransomware" data-type="indexterm" id="ch02.html_ix7">&nbsp;</a>For example, in June 2018 the US Department of Justice indicted Park Jin Hyok, a North Korean citizen accused of participating in <a href="https://www.justice.gov/opa/press-release/file/1092091/download">a wide variety of activities</a> on behalf of his government, including creating the infamous 2017 WannaCry Ransomware (used for financial gain), the 2014 compromise of Sony Pictures (intended to coerce Sony into not releasing a controversial movie, and ultimately harming the company’s infrastructure), and the compromise of electric utilities (presumably for espionage or destructive purposes). Researchers have also observed government attackers using the same malware leveraged in nation-state attacks to <a href="https://media.kasperskycontenthub.com/wp-content/uploads/sites/43/2018/03/20134508/winnti-more-than-just-a-game-130410.pdf">pilfer electronic money</a> in video games for personal gain.</p>
<p>When designing systems, it’s important to keep these diverse motivations in mind. Consider an organization that is processing money transfers on behalf of its customers. If we understand why an attacker might be interested in this system, we can design the system more securely. A good example of possible motivations in this case can be seen in the activities of a group of North Korean government attackers (including Park) who allegedly <a href="https://content.fireeye.com/apt/rpt-apt38">attempted to steal millions of dollars</a> by breaking into banking systems and exploiting the SWIFT transaction system to transfer money out of customer accounts.</p>
</section>
<section data-type="sect1" class="pagebreak-before" id="attacker_profiles">
<h1 class="less_space">Attacker Profiles</h1>
<p><a contenteditable="false" data-primary="adversaries, understanding" data-secondary="attacker profiles" data-type="indexterm" id="ch02.html_ix8">&nbsp;</a><a contenteditable="false" data-primary="attacker profiles" data-type="indexterm" id="ch02.html_ix9">&nbsp;</a><a contenteditable="false" data-primary="profile, attacker" data-type="indexterm" id="ch02.html_ix10">&nbsp;</a>We can better understand attacker motivations by taking the people themselves into account: who they are, whether they perform attacks for themselves or for someone else, and their general interests. In this section, we outline some <em>profiles</em> of attackers, indicating how they relate to a system designer and including a few tips for protecting your systems from these types of attackers. For the sake of brevity, we’ve taken some liberties with generalizations, but remember: no two attacks or attackers are the same. This information is meant to be illustrative rather than definitive.</p>
<aside data-type="sidebar" id="early_hacking">
<h5>Early Hacking</h5>
<p><a contenteditable="false" data-primary="hacking (origin of term)" data-type="indexterm" id="ch02.html_ix11">&nbsp;</a><a contenteditable="false" data-primary="MIT (Massachusetts Institute of Technology)" data-type="indexterm" id="ch02.html_ix12">&nbsp;</a>MIT is considered to be the birthplace of the term <em>hacking</em>, which dates back to the 1950s, when this activity spawned from innocent pranks. These benign origins have led some to differentiate “hacking” and “attacking” into separate notions of nonmalicious and malicious behavior. We continue this tradition throughout this book. The MIT hacker community today operates by a loose set of ethics documented in <a href="https://handbook.mit.edu/hacking">the MIT Mind and Hand Book</a>.</p>
</aside>
<section data-type="sect2" id="hobbyists">
<h2>Hobbyists</h2>
<p><a contenteditable="false" data-primary="adversaries, understanding" data-secondary="hobbyists" data-type="indexterm" id="ch02.html_ix13">&nbsp;</a><a contenteditable="false" data-primary="attacker profiles" data-secondary="hobbyists" data-type="indexterm" id="ch02.html_ix14">&nbsp;</a><a contenteditable="false" data-primary="hobbyists, as attackers" data-type="indexterm" id="ch02.html_ix15">&nbsp;</a>The first computer hackers were <em>hobbyists</em>—curious technologists who wanted to understand how systems worked. In the process of taking computers apart or debugging their programs, these “hackers” discovered flaws that the original system designers hadn’t noticed. Generally speaking, hobbyists are motivated by their thirst for knowledge; they hack for fun, and can be allies to developers looking to build resilience into a system. More often than not, hobbyists abide by personal ethics about not harming systems and don’t cross boundaries into criminal behavior. By leveraging insight into how these hackers think about problems, you can make your systems more secure.</p>
</section>
<section data-type="sect2" id="vulnerability_researchers">
<h2>Vulnerability Researchers</h2>
<p><a contenteditable="false" data-primary="adversaries, understanding" data-secondary="vulnerability researchers" data-type="indexterm" id="ch02.html_ix16">&nbsp;</a><a contenteditable="false" data-primary="attacker profiles" data-secondary="vulnerability researchers" data-type="indexterm" id="ch02.html_ix17">&nbsp;</a><a contenteditable="false" data-primary="vulnerability researchers, as attackers" data-type="indexterm" id="ch02.html_ix18">&nbsp;</a><em>Vulnerability researchers</em> use their security expertise professionally. They enjoy finding security flaws as full-time employees, part-time freelancers, or even accidentally as average users who stumble across bugs. <a contenteditable="false" data-primary="bug bounties (Vulnerability Reward Programs)" data-type="indexterm" id="ch02.html_ix19">&nbsp;</a><a contenteditable="false" data-primary="Vulnerability Reward Programs (bug bounties)" data-type="indexterm" id="ch02.html_ix20">&nbsp;</a>Many researchers participate in Vulnerability Reward Programs, also known as <em>bug bounties</em> (see <a data-type="xref" href='ch20.html#twozero_understanding_roles_and_respons'>Chapter 20</a>).</p>
<p>Vulnerability researchers are typically motivated to make systems better, and can be important allies to organizations seeking to secure their systems. They tend to operate within a set of predictable disclosure norms that set expectations between system owners and researchers about how vulnerabilities are discovered, reported, fixed, and discussed. Researchers operating under these norms avoid inappropriately accessing data, causing harm, or breaking the law. Typically, operating outside these norms invalidates the possibility of getting a reward and may qualify as criminal behavior.</p>
<p><a contenteditable="false" data-primary="penetration testers" data-type="indexterm" id="ch02.html_ix21">&nbsp;</a><a contenteditable="false" data-primary="Red Teams" data-type="indexterm" id="ch02.html_ix22">&nbsp;</a>Relatedly, <em>Red Teams</em> and penetration testers attack targets with the permission of the system owner, and may be hired explicitly for these exercises. Like researchers, they look for ways to defeat system security with a focus on improving security and operate within a set of ethical guidelines. For more discussion on Red Teams, see <span class="keep-together"><a data-type="xref" href='ch20.html#twozero_understanding_roles_and_respons'>Chapter 20</a></span>.</p>
</section>
<section data-type="sect2" id="governments_and_law_enforcement">
<h2>Governments and Law Enforcement</h2>
<p><a contenteditable="false" data-primary="attacker profiles" data-secondary="governments" data-type="indexterm" id="ch02.html1">&nbsp;</a><a contenteditable="false" data-primary="governments" data-secondary="as attackers" data-type="indexterm" id="ch02.html2">&nbsp;</a><a contenteditable="false" data-primary="law enforcement agencies" data-secondary="as attackers" data-type="indexterm" id="ch02.html3">&nbsp;</a><em>Government organizations</em> (for example, law enforcement agencies and intelligence agencies) may hire security experts to gather intelligence, police domestic crime, commit economic espionage, or complement military operations. By now, most national governments have invested in fostering security expertise for these purposes. In some cases, governments may turn to talented students fresh out of school, reformed attackers who have spent time in jail, or notable luminaries in the security industry. While we can’t cover these types of attackers extensively here, we provide a few examples of their most common activities.</p>
<section data-type="sect3" id="intelligence_gathering">
<h3>Intelligence gathering</h3>
<p><a contenteditable="false" data-primary="espionage" data-type="indexterm" id="ch02.html_ix23">&nbsp;</a><a contenteditable="false" data-primary="governments" data-secondary="intelligence gathering" data-type="indexterm" id="ch02.html_ix24">&nbsp;</a><a contenteditable="false" data-primary="intelligence gathering" data-type="indexterm" id="ch02.html_ix25">&nbsp;</a>Intelligence gathering is probably the most publicly discussed government activity that employs people who know how to break into systems. In the past few decades, traditional spying techniques, including signals intelligence (SIGINT) and human intelligence (HUMINT), have modernized with the advent of the internet. <a contenteditable="false" data-primary="RSA" data-type="indexterm" id="ch02.html_ix26">&nbsp;</a>In one famous example from 2011, <a href="https://www.nytimes.com/2011/05/28/business/28hack.html">the security company RSA was compromised</a> by an adversary many experts associate with <a href="https://www.cnet.com/news/china-linked-to-new-breaches-tied-to-rsa/">China’s intelligence apparatus</a>. The attackers compromised RSA to steal cryptographic seeds for their popular two-factor authentication tokens. Once they had these seeds, the attackers didn’t need physical tokens to generate one-time authentication credentials to log in to the systems of <a contenteditable="false" data-primary="Lockheed Martin" data-type="indexterm" id="ch02.html_ix27">&nbsp;</a>Lockheed Martin, a defense contractor that builds technology for the US military. Once upon a time, breaking into a company like Lockheed would have been performed by human operatives onsite—for example, by bribing an employee or having a spy hired at the firm. The advent of systems intrusion, however, has enabled attackers to use more sophisticated electronic techniques to obtain secrets in new ways.</p>
</section>
<section data-type="sect3" id="military_purposes">
<h3>Military purposes</h3>
<p><a contenteditable="false" data-primary="cyber warfare" data-type="indexterm" id="ch02.html_ix28">&nbsp;</a><a contenteditable="false" data-primary="governments" data-secondary="military purposes of attacks" data-type="indexterm" id="ch02.html_ix29">&nbsp;</a><a contenteditable="false" data-primary="information warfare" data-type="indexterm" id="ch02.html_ix30">&nbsp;</a><a contenteditable="false" data-primary="military, cyber warfare and" data-type="indexterm" id="ch02.html_ix31">&nbsp;</a>Governments may break into systems for military purposes—what specialists often refer to as <em>cyber warfare</em> or <em>information warfare</em>. Imagine that a government wants to invade another country. Could they somehow attack the target’s air defense systems and trick them into not recognizing an inbound air force? Could they shut down their power, water, or banking systems?<sup><a data-type="noteref" id="ch02fn2-marker" href="#ch02fn2">2</a></sup> Alternatively, imagine that a government wants to prevent another country from building or obtaining a weapon. Could they remotely and stealthily disrupt their progress? <a contenteditable="false" data-primary="Iran" data-type="indexterm" id="ch02.html_ix32">&nbsp;</a>This scenario supposedly happened in Iran in the late 2000s, when attackers illicitly introduced a modularized piece of software onto the control systems of centrifuges used to enrich uranium. Dubbed <a href="https://en.wikipedia.org/wiki/Stuxnet"><em>Stuxnet</em></a> by researchers, this operation reportedly intended to destroy the centrifuges and halt Iran’s nuclear program.</p>
</section>
<section data-type="sect3" id="policing_domestic_activity">
<h3>Policing domestic activity</h3>
<p><a contenteditable="false" data-primary="governments" data-secondary="cyber attacks as domestic activity monitoring" data-type="indexterm" id="ch02.html_ix33">&nbsp;</a><a contenteditable="false" data-primary="law enforcement agencies" data-secondary="cyber attacks as domestic activity monitoring" data-type="indexterm" id="ch02.html_ix34">&nbsp;</a>Governments may also break into systems to police domestic activity. <a contenteditable="false" data-primary="NSO Group" data-type="indexterm" id="ch02.html_ix35">&nbsp;</a>In a recent example, NSO Group, a cybersecurity contractor, sold software to various governments that allowed private surveillance of communications between people without their knowledge (through the remote monitoring of mobile phone calls). Reportedly, this software was intended to surveil terrorists and criminals—relatively noncontroversial targets. Unfortunately, some of NSO Group’s government customers have also used the software to listen in on journalists and activists, in some cases leading to harassment, arrest, and even possibly death.<sup><a data-type="noteref" id="ch02fn3-marker" href="#ch02fn3">3</a></sup> The ethics of governments using these capabilities against their own people is a hotly debated topic, especially in countries without strong legal frameworks and proper oversight.</p>
</section>
<section data-type="sect3" id="protecting_your_systems_from_nation_sta">
<h3>Protecting your systems from nation-state actors</h3>
<p><a contenteditable="false" data-primary="governments" data-secondary="protecting systems from nation-state actors" data-type="indexterm" id="ch02.html_ix36">&nbsp;</a><a contenteditable="false" data-primary="nation-state actors, protecting systems from" data-seealso="governments" data-type="indexterm" id="ch02.html_ix37">&nbsp;</a>System designers should carefully consider whether they could be the target of a nation-state actor. To this end, you need to understand activities carried out by your organization that may be attractive to these actors. Consider a technology company that builds and sells microprocessor technology to a military branch of the government. It’s possible that other governments would also be interested in having those chips, and may resort to stealing their designs via electronic means.</p>
<p>Your service may also have data that a government wants but that is otherwise difficult for it to obtain. Generally speaking, intelligence agencies and law enforcement value personal communications, location data, and similar types of sensitive personal information. In January 2010, <a href="https://googleblog.blogspot.com/2010/01/new-approach-to-china.html">Google announced</a> it had witnessed a sophisticated targeted attack from China <a contenteditable="false" data-primary="Operation Aurora" data-type="indexterm" id="ch02.html_ix38">&nbsp;</a>(dubbed "Operation Aurora" by researchers) against its corporate infrastructure that is now widely understood to have been aimed at long-term access to Gmail accounts. Storing the personal <span class="keep-together">information</span> of customers, <span class="keep-together">especially</span> private communications, can raise the risk that an intelligence or law enforcement agency would be interested in your systems.</p>
<p>Sometimes you might be a target without realizing it. Operation Aurora wasn’t limited to large tech companies—it affected at least 20 victims in a variety of finance, technology, media, and chemical sectors. These organizations were both large and small, and many did not consider themselves at risk of a nation-state attack.</p>
<p>Consider, for example, an app that aims to provide athletes with data tracking analytics, including where they cycle or run. Would this data be an attractive target to an intelligence agency? <a contenteditable="false" data-primary="Strava" data-type="indexterm" id="ch02.html_ix39">&nbsp;</a>Analysts looking at a public heatmap created by the fitness tracking company Strava considered this exact question in 2018 when they noticed that the <a href="https://www.theguardian.com/world/2018/jan/28/fitness-tracking-app-gives-away-location-of-secret-us-army-bases">locations of secret military bases in Syria were revealed</a> when US troops used the service to track their workouts.</p>
<p>System designers should also be aware that governments can typically deploy significant resources to obtain access to data that they’re interested in. Mounting a defense against a government that’s interested in your data might require far and above the resources your organization can dedicate to implementing security solutions. We recommend that organizations take the long view with regard to building security defenses by investing early in protecting their most sensitive assets, and by having a continued rigorous program that can apply new layers of protections over time. An ideal outcome is forcing an adversary to expend a significant amount of their resources to target you—increasing their risk of being caught—so that their activities can be revealed to other possible victims and government authorities.<a contenteditable="false" data-primary="" id="ch02.html3-eot" data-startref="ch02.html3" data-type="indexterm">&nbsp;</a><a contenteditable="false" data-primary="" id="ch02.html2-eot" data-startref="ch02.html2" data-type="indexterm">&nbsp;</a><a contenteditable="false" data-primary="" id="ch02.html1-eot" data-startref="ch02.html1" data-type="indexterm">&nbsp;</a></p>
</section>
</section>
<section data-type="sect2" id="activists">
<h2>Activists</h2>
<p><a contenteditable="false" data-primary="activists, as attackers" data-type="indexterm" id="ch02.html_ix40">&nbsp;</a><a contenteditable="false" data-primary="attacker profiles" data-secondary="activists/hacktivists" data-type="indexterm" id="ch02.html_ix41">&nbsp;</a><a contenteditable="false" data-primary="hacktivists" data-secondary="as attackers" data-type="indexterm" id="ch02.html_ix42">&nbsp;</a><em>Hacktivism</em> is the act of using technology to call for social change. This term is loosely applied to a wide variety of online political activities, from the subversion of government surveillance to the malicious disruption of systems.<sup><a data-type="noteref" id="ch02fn4-marker" href="#ch02fn4">4</a></sup> For the purpose of thinking about how to design systems, we consider the latter case here.</p>
<p><a contenteditable="false" data-primary="defacing of websites" data-type="indexterm" id="ch02.html_ix43">&nbsp;</a>Hacktivists have been known to <em>deface</em> websites—that is, replace normal content with a political message. In <a href="https://www.washingtonpost.com/news/the-switch/wp/2015/06/08/the-u-s-armys-main-web-site-is-down-and-the-syrian-electronic-army-is-claiming-credit">one example from 2015</a>, the <a contenteditable="false" data-primary="Syrian Electronic Army" data-type="indexterm" id="ch02.html_ix44">&nbsp;</a>Syrian Electronic Army—a collective of malicious actors operating in support of the regime of Bashar al-Assad—took over a content distribution network (CDN) that served web traffic for <a href="http://www.army.mil"><em>www.army.mil</em></a>. The attackers were then able to insert a pro-Assad message subsequently seen by visitors to the website. This kind of attack can be very embarrassing for website owners and can undermine user trust in the site.</p>
<p>Other hacktivist attacks may be far more destructive. For example, in November 2012 the decentralized, <a contenteditable="false" data-primary="Anonymous (hacktivist group)" data-type="indexterm" id="ch02.html_ix45">&nbsp;</a><a contenteditable="false" data-primary="distributed denial-of-service (DDoS) attacks" data-secondary="Anonymous&#39;s attack on Israeli websites" data-type="indexterm" id="ch02.html_ix46">&nbsp;</a><a contenteditable="false" data-primary="Israel" data-type="indexterm" id="ch02.html_ix47">&nbsp;</a>international hacktivist group Anonymous<sup><a data-type="noteref" id="ch02fn5-marker" href="#ch02fn5">5</a></sup> <a href="https://edition.cnn.com/2012/11/19/tech/web/cyber-attack-israel-anonymous/index.html">took numerous Israeli websites offline</a> through denial-of-service attacks. As a result, anyone visiting the affected websites experienced slow service or an error. Distributed denial-of-service attacks of this nature send the victim a flood of traffic from thousands of compromised machines distributed across the world. Brokers of these so-called botnets often provide this sort of capability for purchase online, making the attacks common and easy to carry out. On the more serious end of the spectrum, attackers may even threaten to destroy or sabotage systems entirely, inspiring some researchers to label them cyberterrorists.</p>
<p>Unlike other types of attackers, hacktivists are usually vocal about their activity and often take credit publicly. This can manifest itself in numerous ways, including posting on social media or destroying systems. Activists involved in such attacks may not even be very technically savvy. This can make predicting or defending against hacktivism difficult.</p>
<section data-type="sect3" id="protecting_your_systems_from_hacktivist">
<h3>Protecting your systems from hacktivists</h3>
<p><a contenteditable="false" data-primary="hacktivists" data-secondary="protecting systems from" data-type="indexterm" id="ch02.html_ix48">&nbsp;</a>We recommend thinking about whether your business or project is involved in controversial topics that may draw the attention of activists. For example, does your website allow users to host their own content, like blogs or videos? Does your project involve a politically oriented issue like animal rights? Do activists use any of your products, such as a messaging service? If the answer to any of these questions is "yes," you may need to consider very robust, layered security controls that ensure your systems are patched against vulnerabilities and resilient to DoS attacks, and that your backups can restore a system and its data quickly.</p>
</section>
</section>
<section data-type="sect2" id="criminal_actors">
<h2>Criminal Actors</h2>
<p><a contenteditable="false" data-primary="attacker profiles" data-secondary="criminal actors" data-type="indexterm" id="ch02.html4">&nbsp;</a><a contenteditable="false" data-primary="criminal actors" data-secondary="as attackers" data-type="indexterm" id="ch02.html5">&nbsp;</a>Attack techniques are used to carry out crimes that closely resemble their nondigital cousins—for example, committing identity fraud, stealing money, and blackmail. <em>Criminal actors</em> have a wide range of technical abilities. Some may be sophisticated and write their own tools. Others may purchase or borrow tools that other people build, relying on their easy, click-to-attack interfaces. In fact, <em>social engineering</em>—the act of tricking a victim into aiding you in the attack—is highly effective despite being at the lowest end of difficulty. The only barriers to entry for most criminal actors are a bit of time, a computer, and a little cash.</p>
<p>Presenting a full catalog of the kinds of criminal activities that occur in the digital realm would be impossible, but we provide a few illustrative examples here. For example, imagine that you wanted to predict merger and acquisition activities so you could time certain stock trades accordingly. <a contenteditable="false" data-primary="China" data-type="indexterm" id="ch02.html_ix49">&nbsp;</a>Three criminal actors in China had this exact idea in 2014–2015 and <a href="https://www.sec.gov/news/pressrelease/2016-280.html">made a few million dollars</a> by stealing sensitive information from unsuspecting law firms.</p>
<p>In the past 10 years, attackers have also realized that victims will hand over money when their sensitive data is threatened. <a contenteditable="false" data-primary="ransomware attacks" data-type="indexterm" id="ch02.html_ix50">&nbsp;</a><em>Ransomware</em> is software that holds a system or its information hostage (usually by encrypting it) until the victim makes a payment to the attacker. Commonly, attackers infect victim machines with this software (which is often packaged and sold to attackers as a toolkit) by exploiting vulnerabilities, by packaging the ransomware with legitimate software, or by tricking the user into installing it themselves.</p>
<p>Criminal activity does not always manifest as overt attempts to steal money. <a contenteditable="false" data-primary="stalkerware" data-type="indexterm" id="ch02.html_ix51">&nbsp;</a><em>Stalkerware</em>—spying software that’s often sold for as little as $20—aims to gather information about another person without their knowledge. The malicious software is introduced onto a victim’s computer or mobile phone either by tricking the victim into installing it or via direct installation by an attacker with access to the device. Once in place, the software can record video and audio. Since <a href="https://ieeexplore.ieee.org/document/8418618">stalkerware is often used by people close to the victim</a>, such as a spouse, this kind of trust exploitation can be devastatingly effective.</p>
<p>Not all criminal actors work for themselves. Companies, law firms, political campaigns, cartels, gangs, and other organizations hire malicious actors for their own purposes. <a contenteditable="false" data-primary="Colombia" data-type="indexterm" id="ch02.html_ix52">&nbsp;</a><a contenteditable="false" data-primary="elections, hacking of" data-type="indexterm" id="ch02.html_ix53">&nbsp;</a>For example, <a href="https://www.bloomberg.com/features/2016-how-to-hack-an-election/">a Colombian attacker</a> claimed he was hired to assist a candidate in the 2012 presidential race in Mexico and other elections throughout Latin America by stealing opposition information and spreading misinformation. <a contenteditable="false" data-primary="Cellcom" data-type="indexterm" id="ch02.html_ix54">&nbsp;</a><a contenteditable="false" data-primary="Liberia" data-type="indexterm" id="ch02.html_ix55">&nbsp;</a><a contenteditable="false" data-primary="Lonestar" data-type="indexterm" id="ch02.html_ix56">&nbsp;</a>In a stunning case from Liberia, an employee of Cellcom, a mobile phone service provider, reportedly <a href="https://www.bbc.com/news/uk-46840461">hired an attacker</a> to degrade the network of its rival cellular service provider, Lonestar. These attacks disrupted Lonestar’s ability to serve its customers, causing the company to lose significant amounts of revenue.</p>
<section data-type="sect3" id="protecting_your_systems_from_criminal_a">
<h3>Protecting your systems from criminal actors</h3>
<p><a contenteditable="false" data-primary="criminal actors" data-secondary="protecting your systems from" data-type="indexterm" id="ch02.html_ix57">&nbsp;</a>When designing systems to be resilient against criminal actors, keep in mind that these actors tend to gravitate toward the easiest way to meet their goals with the least up-front cost and effort. If you can make your system resilient enough, they may shift their focus to another victim. Therefore, consider which systems they might target, and how to make their attacks expensive. <a contenteditable="false" data-primary="CAPTCHA (Completely Automated Public Turing test) systems" data-type="indexterm" id="ch02.html_ix58">&nbsp;</a>The evolution of Completely Automated Public Turing test (CAPTCHA) systems is a good example of how to increase the cost of attacks over time. CAPTCHAs are used to determine whether a human or an automated bot is interacting with a website—for example, during a login. Bots are often a sign of malicious activity, so being able to determine if the user is human can be an important signal. Early CAPTCHA systems asked humans to validate slightly distorted letters or numbers that bots had a difficult time recognizing. As the bots became more sophisticated, CAPTCHA implementers began using distortion pictures and object recognition. These tactics aimed to significantly increase the cost of attacking CAPTCHAs over time.<sup><a data-type="noteref" id="ch02fn6-marker" href="#ch02fn6">6</a></sup></p>
</section>
</section>
<section data-type="sect2" id="automation_and_artificial_intelligence">
<h2>Automation and Artificial Intelligence</h2>
<p><a contenteditable="false" data-primary="artificial intelligence" data-secondary="cyber attacks and" data-type="indexterm" id="ch02.html_ix59">&nbsp;</a><a contenteditable="false" data-primary="automated attacks" data-type="indexterm" id="ch02.html_ix60">&nbsp;</a><a contenteditable="false" data-primary="automation" data-secondary="cyber attacks and" data-type="indexterm" id="ch02.html_ix61">&nbsp;</a><a contenteditable="false" data-primary="Cyber Grand Challenge" data-type="indexterm" id="ch02.html_ix62">&nbsp;</a><a contenteditable="false" data-primary="DARPA (Defense Advanced Research Projects Agency)" data-type="indexterm" id="ch02.html_ix63">&nbsp;</a><a contenteditable="false" data-primary="Defense Advanced Research Projects Agency (DARPA)" data-type="indexterm" id="ch02.html_ix64">&nbsp;</a>In 2015, the US Defense Advanced Research Projects Agency (DARPA) announced the <a href="https://www.darpa.mil/program/cyber-grand-challenge">Cyber Grand Challenge contest</a> to design a cyber-reasoning system that could self-learn and operate without human intervention to find flaws in software, develop ways to exploit these flaws, and then patch against the exploitations. Seven teams participated in a live “final event” and watched their fully independent reasoning systems attack each other from the comfort of a large ballroom. The first-place team succeeded in developing such a self-learning system!</p>
<p>The success of the Cyber Grand Challenge suggests that it’s likely at least some attacks in the future could be executed without humans directly at the controls. Scientists and ethicists ponder whether fully sentient machines might be capable enough to learn how to attack each other. The notion of autonomous attack platforms is also prompting the need for increasingly automated defenses, which we predict will be an important area of research for future system designers.</p>
<section data-type="sect3" id="protecting_your_systems_from_automated">
<h3>Protecting your systems from automated attacks</h3>
<p><a contenteditable="false" data-primary="artificial intelligence" data-secondary="protecting systems from automated attacks" data-type="indexterm" id="ch02.html_ix65">&nbsp;</a>To withstand the onslaught of automated attacks, developers need to consider resilient system design by default, and be able to automatically iterate the security posture of their systems. We cover many of these topics in this book, such as automated configuration distribution and access justifications in <a data-type="xref" href='ch05.html#design_for_least_privilege'>Chapter 5</a>; automated build, test, and deployment of code in <a data-type="xref" href='ch14.html#onefour_deploying_code'>Chapter 14</a>; and handling DoS attacks in <a data-type="xref" href='ch08.html#design_for_resilience'>Chapter 8</a>.</p>
</section>
</section>
<section data-type="sect2" id="insiders">
<h2>Insiders</h2>
<p><a contenteditable="false" data-primary="attacker profiles" data-secondary="insiders" data-type="indexterm" id="ch02.html6">&nbsp;</a><a contenteditable="false" data-primary="insiders" data-secondary="attacks by" data-type="indexterm" id="ch02.html7">&nbsp;</a>Every organization has <em>insiders</em>: current or former employees who are trusted with internal access to systems or proprietary knowledge. <a contenteditable="false" data-primary="insider risk" data-secondary="defined" data-type="indexterm" id="ch02.html_ix66">&nbsp;</a><em>Insider risk</em> is the threat posed by such individuals. <a contenteditable="false" data-primary="insider threat" data-type="indexterm" id="ch02.html_ix67">&nbsp;</a>A person becomes an <em>insider threat</em> when they are able to perform actions that cover a wide range of malicious, negligent, or accidental scenarios that could result in harm to the organization. Insider risk is a large topic that could fill the pages of several books. To help system designers, we cover the topic briefly here by considering three general categories, as outlined in <a data-type="xref" href="#general_categories_of_insiders_and_exam">#general_categories_of_insiders_and_exam</a>.</p>
<table class="border" id="general_categories_of_insiders_and_exam">
<caption>General categories of insiders and examples</caption>
<thead>
<tr>
<th width="20%">First-party insiders</th>
<th width="30%">Third-party insiders</th>
<th>Related insiders</th>
</tr>
</thead>
<tbody>
<tr>
<td>Employees<br/>Interns<br/>Executives<br/>Board directors</td>
<td>Third-party app developers<br/>Open source contributors<br/>Trusted content contributors<br/>Commercial partners<br/>Contractors<br/>Vendors<br/>Auditors</td>
<td>Friends<br/>Family<br/>Roommates</td>
</tr>
</tbody>
</table>
<aside data-type="sidebar" id="intersection_of_reliability_and_securit">
<h5>Intersection of Reliability and Security: Effects of Insiders</h5>
<p><a contenteditable="false" data-primary="intersection of security and reliability" data-secondary="effects of insiders" data-type="indexterm" id="ch02.html_ix68">&nbsp;</a>When it comes to protecting against adversaries, reliability and security intersect most when you’re designing systems to be resilient against insiders. This intersection is largely due to the privileged access insiders have to your systems. Most reliability incidents stem from actions taken by an insider who often doesn’t realize how they’re impacting the system—for example, by introducing faulty code or an errant configuration change. On the security side, if an attacker can take over an employee’s account, then the attacker can act maliciously against your systems as if they were that insider. Any permissions or privileges you assign to your insiders become available to an attacker.</p>
<p>When designing systems to be both reliable and secure, it’s best practice to consider both well-intended insiders who might make mistakes and attackers who might take over an employee account. For example, if you have a database with sensitive customer information that’s critical to your business, you likely want to prevent employees from accidentally deleting the database while performing maintenance work. You also want to protect database information from an attacker that hijacks an employee’s account. Techniques for least privilege, outlined in <a data-type="xref" href='ch05.html#design_for_least_privilege'>Chapter 5</a>, protect against both reliability and security risks.</p>
</aside>
<section data-type="sect3" id="first_party_insiders">
<h3>First-party insiders</h3>
<p><a contenteditable="false" data-primary="first-party insiders" data-type="indexterm" id="ch02.html_ix69">&nbsp;</a><a contenteditable="false" data-primary="insiders" data-secondary="first-party" data-type="indexterm" id="ch02.html_ix70">&nbsp;</a><em>First-party insiders</em> are people brought into the fold for a specific purpose—usually to participate directly in meeting business objectives. This category includes employees who directly work for the company, executives, and members of the board who make critical company decisions. You can probably think of other people who fall into the category too. Insiders with first-party access to sensitive data and systems make up the majority of news stories about insider risk. <a contenteditable="false" data-primary="General Electric (GE)" data-type="indexterm" id="ch02.html_ix71">&nbsp;</a>Take the case of the <a href="https://www.justice.gov/opa/press-release/file/1156521/download">engineer working for General Electric</a> who was indicted in April 2019 on charges of stealing proprietary files, embedding them into photos using steganographic software (in order to conceal their theft), and sending them to his personal email account. Prosecutors allege that his goal was to enable him and his business partner in China to produce low-cost versions of GE’s turbomachines and sell them to the Chinese government. Stories like this are prevalent throughout high-tech firms that produce next-generation <span class="keep-together">technology</span>.</p>
<p>Access to personal data can also be tempting to insiders with voyeuristic tendencies, people who want to seem important for having privileged access, and even people who want to sell such information. <a contenteditable="false" data-primary="UCLA Medical Center" data-type="indexterm" id="ch02.html_ix72">&nbsp;</a>In <a href="https://www.latimes.com/archives/la-xpm-2008-mar-15-me-britney15-story.html">an infamous case from 2008</a>, several hospital workers were fired from UCLA Medical Center after inappropriately looking at the files of patients, including high-profile celebrities. As more and more consumers sign up for social networking, messaging, and banking services, protecting their data from inappropriate employee access is more important than ever.</p>
<p>Some of the most radical stories of insider risk involve disgruntled insiders. In January 2019, a man who had been fired for poor performance was convicted of <a href="https://www.infosecurity-magazine.com/infosec/poor-security-let-rogue-employee-1/">deleting 23 of his former employer’s virtual servers</a>. The incident lost the company key contracts and significant revenue. Almost any company that’s been around for a while has similar stories. Because of the dynamics of employment relationships, this risk is unavoidable.</p>
<p>The preceding examples cover scenarios in which someone with malicious intent affects the security of systems and information. However, as some examples earlier in the book illustrate, first-party insiders can also impact the reliability of systems. For example, the previous chapter discusses a string of unfortunate insider actions in the design, operation, and maintenance of a password storage system that prevented SREs from accessing credentials in an emergency. As we’ll see, anticipating the mistakes that insiders can introduce is vital to guaranteeing system integrity.</p>
</section>
<section data-type="sect3" id="third_party_insiders">
<h3>Third-party insiders</h3>
<p><a contenteditable="false" data-primary="insiders" data-secondary="third-party" data-type="indexterm" id="ch02.html_ix73">&nbsp;</a><a contenteditable="false" data-primary="open source components" data-secondary="third-party insider threats" data-type="indexterm" id="ch02.html_ix74">&nbsp;</a><a contenteditable="false" data-primary="third-party insiders" data-type="indexterm" id="ch02.html_ix75">&nbsp;</a>With the rise of open source software and open platforms, it’s increasingly likely that an insider threat may be someone whom few people (or no one) in your organization have ever met. Consider the following scenario: your company has developed a new library that’s helpful for processing images. You decide to open source the library and accept code change lists from the public. In addition to company employees, you now have to consider open source contributors as insiders. After all, if an open source contributor on the other side of the world whom you’ve never met submits a malicious change list, they can harm people using your library.</p>
<p>Similarly, open source developers rarely have the ability to test their code in all environments where it might be deployed. Additions to the codebase might introduce unpredictable reliability issues, such as unanticipated performance degradations or hardware compatibility issues. In this scenario, you’d want to implement controls ensuring that all submitted code is thoroughly reviewed and tested. For more details on best practices in this area, see Chapters <a data-type="xref" data-xrefstyle="select:labelnumber" href='ch13.html#onethree_testing_code'>Chapter 13</a> and <a data-type="xref" data-xrefstyle="select:labelnumber" href='ch14.html#onefour_deploying_code'>Chapter 14</a>.</p>
<p><a contenteditable="false" data-primary="APIs (application programming interfaces)" data-secondary="third-party insider threats" data-type="indexterm" id="ch02.html_ix76">&nbsp;</a>You should also think carefully about how you extend a product’s functionality via application programming interfaces (APIs). Suppose your organization develops a human resources platform with a third-party developer API so companies can easily extend the functionality of your software. If the third-party developer has privileged or special access to the data, they may now be an insider threat. Carefully consider the access you’re providing through the API, and what the third party can do once they have access. Can you limit the impact these extended insiders have on system reliability and security?</p>
</section>
<section data-type="sect3" id="related_insiders">
<h3>Related insiders</h3>
<p><a contenteditable="false" data-primary="insiders" data-secondary="related" data-type="indexterm" id="ch02.html_ix77">&nbsp;</a><a contenteditable="false" data-primary="related insiders" data-type="indexterm" id="ch02.html_ix78">&nbsp;</a>It’s not uncommon to implicitly trust the people we live with, but these relationships are often overlooked by system designers when designing secure systems.<sup><a data-type="noteref" id="ch02fn7-marker" href="#ch02fn7">7</a></sup> Consider a situation in which an employee takes their laptop home over the weekend. Who has access to that device when it’s unlocked on the kitchen table, and what impact could they have, either maliciously or unintended? Telecommuting, working from home, and late-night pager duty are increasingly common for technology workers. When considering your insider risk threat model, be sure to use a broad definition of “workplace” that also includes the home. The person behind the keyboard may not always be the “typical” insider.</p>
<aside data-type="sidebar" id="determining_insider_intent">
<h5>Determining Insider Intent</h5>
<p><a contenteditable="false" data-primary="insiders" data-secondary="determining intent of" data-type="indexterm" id="ch02.html_ix79">&nbsp;</a>If a system goes offline because of the actions of an insider, and they claim their actions were an accident, do you believe them? The answer to this question can be difficult to determine, and in extreme cases of negligence, it may be impossible to conclusively confirm or rule out. Such cases often require working with expert investigators, such as your organization’s legal department, human resources, and perhaps even law enforcement. First and foremost, when designing, running, and maintaining your systems, plan for both malicious and unintended actions, and assume you may not always know the difference.</p>
</aside>
</section>
<section data-type="sect3" id="threat_modeling_insider_risk">
<h3>Threat modeling insider risk</h3>
<p><a contenteditable="false" data-primary="insider risk" data-secondary="threat modeling" data-type="indexterm" id="ch02.html_ix80">&nbsp;</a><a contenteditable="false" data-primary="insiders" data-secondary="threat modeling insider risk" data-type="indexterm" id="ch02.html_ix81">&nbsp;</a><a contenteditable="false" data-primary="threat modeling" data-secondary="insider risk" data-type="indexterm" id="ch02.html_ix82">&nbsp;</a>Numerous frameworks exist for modeling insider risk, ranging from simple to highly topic-specific, sophisticated, and detailed. If your organization needs a simple model to get started, we have successfully used the framework in <a data-type="xref" href="#framework_for_modeling_insider_risk">#framework_for_modeling_insider_risk</a>. This model is also adaptable to a quick brainstorming session or fun card game.</p>
<table class="border" id="framework_for_modeling_insider_risk">
<caption>Framework for modeling insider risk</caption>
<thead>
<tr>
<th width="15%">Actor/Role</th>
<th width="15%">Motive</th>
<th width="15%">Actions</th>
<th>Target</th>
</tr>
</thead>
<tbody>
<tr>
<td>Engineering</td>
<td>Accidental</td>
<td>Data access</td>
<td>User data</td>
</tr>
<tr>
<td>Operations</td>
<td>Negligent</td>
<td>Exfiltration (theft)</td>
<td>Source code</td>
</tr>
<tr>
<td>Sales</td>
<td>Compromised</td>
<td>Deletions</td>
<td>Documents</td>
</tr>
<tr>
<td>Legal</td>
<td>Financial</td>
<td>Modifications</td>
<td>Logs</td>
</tr>
<tr>
<td>Marketing</td>
<td>Ideological</td>
<td>Injections</td>
<td>Infrastructure</td>
</tr>
<tr>
<td>Executives</td>
<td>Retaliatory</td>
<td>Leak to press</td>
<td>Services</td>
</tr>
<tr>
<td> </td>
<td>Vanity</td>
<td> </td>
<td>Financials</td>
</tr>
</tbody>
</table>
<p>First, establish a list of <em>actors/roles</em> present in your organization. Attempt to think of all the <em>actions</em> that may cause harm (including accidents) and potential <em>targets</em> (data, systems, etc.). You can combine items from each category to create many scenarios. Here are some examples to get you started:</p>
<ul>
<li><p>An <em>engineer</em> with access to <em>source code</em> is unsatisfied with their performance review and <em>retaliates</em> by injecting a malicious backdoor into production that steals <em>user data</em>.</p></li>
<li><p>An <em>SRE</em> with access to the website’s SSL <em>encryption keys</em> is approached by a stranger and is <em>strongly encouraged</em> (for example, via threats to their family) to hand over sensitive material.</p></li>
<li><p>A <em>financial analyst</em> preparing the <em>company financials</em> is working overtime and <em>accidentally</em> modifies the <em>final yearly revenue numbers</em> by a factor of 1,000%.</p></li>
<li><p>An <em>SRE’s child</em> uses their parent’s laptop at home and installs a game bundled with <em>malware</em> that locks the computer and <em>prevents the SRE from responding</em> to a serious outage.</p></li>
</ul>
<aside data-type="sidebar" class="pagebreak-before less_space" id="threat_modeling_mistakes">
<h5>Threat Modeling Mistakes</h5>
<p><a contenteditable="false" data-primary="errors, threat modeling and" data-type="indexterm" id="ch02.html_ix83">&nbsp;</a><a contenteditable="false" data-primary="mistakes, threat modeling and" data-type="indexterm" id="ch02.html_ix84">&nbsp;</a><a contenteditable="false" data-primary="threat modeling" data-secondary="mistakes and" data-type="indexterm" id="ch02.html_ix85">&nbsp;</a>Sometimes people just make mistakes—to err is human. <a contenteditable="false" data-primary="Google Search" data-type="indexterm" id="ch02.html_ix86">&nbsp;</a>For around 40 minutes on January 31, 2009, Google Search displayed an ominous warning—“This site may harm your computer”—to every user, for every search! This warning is normally reserved for search results that link to a website that’s either compromised or hosting malware. The <a href="https://googleblog.blogspot.com/2009/01/this-site-may-harm-your-computer-on.html">root cause</a> of this issue was very simple: a “/” had been implicitly (and accidentally!) added to the system’s list of sites known to install malicious software in the background, which matched every website on the planet.</p>
<p>Given sufficient time working with systems, everyone is likely to encounter some version of this horror story. These mistakes can be caused by working late at night without enough sleep, typos, or simply encountering unforeseen functionality in the system. When designing secure and reliable systems, remember that humans make mistakes, and consider how to prevent them. An automated check on whether “/” was added to the configuration would have prevented the aforementioned outage!</p>
</aside>
</section>
<section data-type="sect3" id="designing_for_insider_risk">
<h3>Designing for insider risk</h3>
<p><a contenteditable="false" data-primary="insider risk" data-secondary="designing for" data-type="indexterm" id="ch02.html_ix87">&nbsp;</a><a contenteditable="false" data-primary="insiders" data-secondary="designing for insider risk" data-type="indexterm" id="ch02.html_ix88">&nbsp;</a>This book presents many design strategies for security that are applicable to protecting against insider risk and malicious “outside” attackers. When designing systems, you must consider that whoever has access to a system or its data could be any of the attacker types outlined in this chapter. Therefore, the strategies for detecting and mitigating both types of risk are similar.</p>
<p>We have found a few concepts to be particularly effective when thinking about insider risk:</p>
<dl>
<dt>Least privilege</dt>
<dd>Granting the fewest privileges necessary to perform job duties, both in terms of scope and duration of access. See <a data-type="xref" href='ch05.html#design_for_least_privilege'>Chapter 5</a>.</dd>
<dt>Zero trust</dt>
<dd>Designing automated or proxy mechanisms for managing systems so that insiders don’t have broad access that allows them to cause harm. See <a data-type="xref" href='ch03.html#case_study_safe_proxies'>Chapter 3</a>.</dd>
<dt>Multi-party authorization</dt>
<dd>Using technical controls to require more than one person to authorize sensitive actions. See <a data-type="xref" href='ch05.html#design_for_least_privilege'>Chapter 5</a>.</dd>
<dt>Business justifications</dt>
<dd>Requiring employees to formally document their reason for accessing sensitive data or systems. See <a data-type="xref" href='ch05.html#design_for_least_privilege'>Chapter 5</a>.</dd>
<dt>Auditing and detection</dt>
<dd>Reviewing all access logs and justifications to make sure they’re appropriate. See <a data-type="xref" href='ch15.html#onefive_investigating_systems'>Chapter 15</a>.</dd>
<dt>Recoverability</dt>
<dd>The ability to recover systems after a destructive action, like a disgruntled employee deleting critical files or systems. See <a data-type="xref" href='ch09.html#design_for_recovery'>Chapter 9</a>.<a contenteditable="false" data-primary="" id="ch02.html7-eot" data-startref="ch02.html7" data-type="indexterm">&nbsp;</a><a contenteditable="false" data-primary="" id="ch02.html6-eot" data-startref="ch02.html6" data-type="indexterm">&nbsp;</a></dd>
</dl>
</section>
</section>
</section>
<section data-type="sect1" id="attacker_methods">
<h1>Attacker Methods</h1>
<p><a contenteditable="false" data-primary="adversaries, understanding" data-secondary="attacker methods" data-type="indexterm" id="ch02.html8">&nbsp;</a><a contenteditable="false" data-primary="attacker methods" data-type="indexterm" id="ch02.html9">&nbsp;</a>How do the threat actors we’ve described carry out their attacks? Knowing the answer to this question is critical for understanding how someone might compromise your systems and, in turn, how you can protect them. Understanding how attackers operate can feel like complex magic. Trying to predict what any particular attacker might do on any given day is unfeasible because of the variety of attack methods available. There is no way for us to present every possible method here, but thankfully, developers and system designers can leverage an increasingly large repository of examples and frameworks to wrap their heads around this problem. In this section, we discuss a few frameworks for studying attacker methods: threat intelligence, cyber kill chains, and TTPs.</p>
<section data-type="sect2" id="threat_intelligence">
<h2>Threat Intelligence</h2>
<p><a contenteditable="false" data-primary="attacker methods" data-secondary="threat intelligence framework for studying" data-type="indexterm" id="ch02.html_ix89">&nbsp;</a><a contenteditable="false" data-primary="threat intelligence" data-type="indexterm" id="ch02.html_ix90">&nbsp;</a>Many security firms produce detailed descriptions of attacks they’ve seen in the wild. This <em>threat intelligence</em> can help system defenders understand how real attackers are working every day and how to repel them. Threat intelligence comes in multiple forms, each serving a different purpose:</p>
<ul>
<li><p><em>Written reports</em> describe how attacks occurred and are especially useful for learning about the progression and intent of an attacker. Such reports are often generated as a result of hands-on response activities and may vary in quality depending on the expertise of the researchers.</p></li>
<li><p><a contenteditable="false" data-primary="indicators of compromise (IOCs)" data-type="indexterm" id="ch02.html_ix91">&nbsp;</a><em>Indicators of compromise</em> (IOCs) are typically finite attributes of an attack, such as the IP address where an attacker hosted a phishing website or the SHA256 checksum of a malicious binary. IOCs are often structured using a common format<sup><a data-type="noteref" id="ch02fn8-marker" href="#ch02fn8">8</a></sup> and obtained through automated feeds so they can be used to programmatically configure detection systems.</p></li>
<li><p><a contenteditable="false" data-primary="malware reports" data-type="indexterm" id="ch02.html_ix92">&nbsp;</a><em>Malware reports</em> provide insight into the capabilities of attacker tools and can be a source of IOCs. <a contenteditable="false" data-primary="reverse engineering" data-type="indexterm" id="ch02.html_ix93">&nbsp;</a>These reports are generated by experts in <em>reverse engineering</em> binaries, usually using standard tools of the trade such as IDA Pro or Ghidra. Malware researchers also use these studies to cross-correlate unrelated attacks according to their common software attributes.</p></li>
</ul>
<p>Acquiring threat intelligence from a reputable security firm—preferably one with customer references—can help you better understand the observed activities of attackers, including attacks affecting peer organizations in your industry. Knowing what kinds of attacks organizations similar to yours are facing can provide an early warning of what you might face someday. Many threat intelligence firms also publicly release yearly summary and trend reports for free.<sup><a data-type="noteref" id="ch02fn9-marker" href="#ch02fn9">9</a></sup></p>
</section>
<section data-type="sect2" id="cyber_kill_chains">
<h2>Cyber Kill Chains™</h2>
<p><a contenteditable="false" data-primary="attacker methods" data-secondary="Cyber Kill Chain framework for studying" data-type="indexterm" id="ch02.html_ix94">&nbsp;</a><a contenteditable="false" data-primary="Cyber Kill Chain" data-type="indexterm" id="ch02.html_ix95">&nbsp;</a>One way of preparing for attacks is to lay out all the possible steps that an attacker may have to take to achieve their goals. Some security researchers use formalized frameworks like the Cyber Kill Chain<sup><a data-type="noteref" id="ch02fn10-marker" href="#ch02fn10">10</a></sup> to analyze attacks this way. These kinds of frameworks can help you plot the formal progression of an attack alongside defensive controls to consider. <a data-type="xref" href="#cyber_kill_chain_of_a_hypothetical_atta">#cyber_kill_chain_of_a_hypothetical_atta</a> shows the stages of a hypothetical attack relative to some defensive layers.</p>
<table class="border" id="cyber_kill_chain_of_a_hypothetical_atta">
<caption>Cyber Kill Chain of a hypothetical attack</caption>
<thead>
<tr>
<th>Attack stage</th>
<th>Attack example</th>
<th>Example defenses</th>
</tr>
</thead>
<tbody>
<tr>
<td><em>Reconnaissance</em>: Surveilling a target victim to understand their weak points.</td>
<td>Attacker uses a search engine to find the email addresses of employees at a target organization.</td>
<td>Educate employees about online safety.</td>
</tr>
<tr>
<td><em>Entry</em>: Gaining access to the network, systems, or accounts necessary to carry out the attack.</td>
<td>Attacker sends phishing emails to employees that lead to compromised account credentials. The attacker then signs in to the organization’s virtual private network (VPN) service using those credentials.</td>
<td>Use two-factor authentication (such as security keys) for the VPN service.<br/>Only permit VPN connections from organization-managed systems.</td>
</tr>
<tr>
<td><em>Lateral movement</em>: Moving between systems or accounts to gain additional access.</td>
<td>Attacker remotely logs in to other systems using the compromised credentials.</td>
<td>Permit employees to log in to only their own systems.<br/>Require two-factor authentication for login to multiuser systems.</td>
</tr>
<tr>
<td><em>Persistence</em>: Ensuring ongoing access to compromised assets.</td>
<td>Attacker installs a backdoor on the newly compromised systems that provides them with remote access.</td>
<td>Use application allowlisting that permits only authorized software to run.</td>
</tr>
<tr>
<td><em>Goals</em>: Taking action on attack goals.</td>
<td>Attacker steals documents from the network and uses the remote access backdoor to exfiltrate them.</td>
<td>Enable least privileged access to sensitive data and monitoring of employee accounts.</td>
</tr>
</tbody>
</table>
</section>
<section data-type="sect2" id="tacticscomma_techniquescomma_and_proced">
<h2>Tactics, Techniques, and Procedures</h2>
<p><a contenteditable="false" data-primary="attacker methods" data-secondary="categorizing of tactics, techniques, and procedures" data-type="indexterm" id="ch02.html_ix96">&nbsp;</a><a contenteditable="false" data-primary="tactics, techniques, and procedures (TTPs)" data-type="indexterm" id="ch02.html_ix97">&nbsp;</a><a contenteditable="false" data-primary="TTPs (tactics, techniques, and procedures)" data-type="indexterm" id="ch02.html_ix98">&nbsp;</a>Methodically categorizing attacker TTPs is an increasingly common way of cataloging attack methods. <a contenteditable="false" data-primary="ATT&amp;CK framework" data-type="indexterm" id="ch02.html_ix99">&nbsp;</a><a contenteditable="false" data-primary="MITRE" data-type="indexterm" id="ch02.html_ix100">&nbsp;</a>Recently, MITRE has developed the <a href="https://attack.mitre.org">ATT&amp;CK framework</a> to instrument this idea more thoroughly. In short, the framework expands each stage of the cyber kill chain into detailed steps and provides formal descriptions of how an attacker could carry out each stage of an attack. For example, in the Credential Access stage, ATT&amp;CK describes how a user’s <em>.bash_history</em> may contain accidentally typed passwords that an attacker could obtain by simply reading the file. The ATT&amp;CK framework lays out hundreds (potentially thousands) of ways attackers can operate so that defenders can build defenses against each attack method.<a contenteditable="false" data-primary="" id="ch02.html9-eot" data-startref="ch02.html9" data-type="indexterm">&nbsp;</a><a contenteditable="false" data-primary="" id="ch02.html8-eot" data-startref="ch02.html8" data-type="indexterm">&nbsp;</a></p>
</section>
</section>
<section data-type="sect1" id="risk_assessment_considerations">
<h1>Risk Assessment Considerations</h1>
<p><a contenteditable="false" data-primary="adversaries, understanding" data-secondary="risk assessment considerations" data-type="indexterm" id="ch02.html10">&nbsp;</a><a contenteditable="false" data-primary="risk assessment" data-secondary="understanding adversaries" data-type="indexterm" id="ch02.html11">&nbsp;</a>Understanding potential adversaries, who they are, and which methods they might use can be complex and nuanced. We have found the following considerations important when assessing the risk posed by various attackers:</p>
<dl>
<dt>You may not realize you’re a target.</dt>
<dd>It may not be immediately obvious that your company, organization, or project is a potential target. Many organizations, despite being small or not involved in handling sensitive information, can be leveraged to carry out attacks. In September 2012, Adobe—a company best known for software that enables content creators—disclosed that <a href="https://blogs.adobe.com/security/2012/09/inappropriate-use-of-adobe-code-signing-certificate.html">attackers had penetrated its networks</a> with the express intent to digitally sign their malware using the company’s official software signing certificate. This enabled the attackers to deploy malware that appeared legitimate to antivirus and other security protection software. Consider whether your organization has assets that an attacker would be interested in, either for direct gain or as part of a larger attack on someone else.</dd>
<dt>Attack sophistication is not a true predictor of success.</dt>
<dd>Even if an attacker has a lot of resources and skills, don’t assume that they’ll always choose the most difficult, expensive, or esoteric means to achieve their goals. Generally speaking, attackers choose the simplest and most cost-effective methods of compromising a system that meet their goals. For example, some of the most prominent and impactful intelligence gathering operations rely on basic <a href="https://googleblog.blogspot.com/2011/06/ensuring-your-information-is-safe.html"><em>phishing</em></a>—tricking a user into handing over their password. For this reason, when designing your systems, be sure to cover the simple basics of security (like using two-factor authentication) before worrying about esoteric and exotic attacks (like firmware backdoors).</dd>
<dt>Don’t underestimate your adversary.</dt>
<dd>Don’t assume that an adversary can’t procure the resources to carry out an expensive or difficult attack. Consider carefully how much your adversary is willing to spend. <a contenteditable="false" data-primary="Cisco" data-type="indexterm" id="ch02.html_ix101">&nbsp;</a><a contenteditable="false" data-primary="NSA" data-type="indexterm" id="ch02.html_ix102">&nbsp;</a>The extraordinary tale of the NSA implanting backdoors in Cisco hardware by intercepting shipments en route to customers illustrates the lengths that well-funded and talented attackers will go to achieve their goals.<sup><a data-type="noteref" id="ch02fn11-marker" href="#ch02fn11">11</a></sup> However, keep in mind that these types of cases are very much the exception rather than the norm.</dd>
<dt>Attribution is hard.</dt>
<dd><p><a contenteditable="false" data-primary="NotPetya ransomware" data-type="indexterm" id="ch02.html_ix103">&nbsp;</a><a contenteditable="false" data-primary="Petya ransomware" data-type="indexterm" id="ch02.html_ix104">&nbsp;</a><a contenteditable="false" data-primary="ransomware attacks" data-secondary="Petya" data-type="indexterm" id="ch02.html_ix105">&nbsp;</a>In March 2016, researchers uncovered a new type of ransomware—a malicious program that renders data or systems unavailable until the victim pays a ransom—which they named Petya. Petya appeared to be financially motivated. A year later, researchers discovered a new piece of malware that shared many elements of the original Petya program. Dubbed <a href="https://www.wired.com/story/notpetya-cyberattack-ukraine-russia-code-crashed-the-world/">NotPetya</a>, the new malware spread globally very quickly, <a contenteditable="false" data-primary="Ukraine" data-type="indexterm" id="ch02.html_ix106">&nbsp;</a>but was primarily found on systems in Ukraine on the eve of a Ukrainian holiday. To deliver NotPetya, attackers compromised a company that made products explicitly for the Ukrainian market and abused their software distribution mechanism to infect victims. Some researchers believe that this attack was carried out by a Russian state-sponsored actor in order to target Ukraine.</p>
<p>This example shows that motivated attackers can hide their motives and identity in creative ways—in this case, by disguising themselves as something potentially more benign. Since the identity and intent of attackers may not always be well understood, we recommend that you focus on how attackers work (their TTPs) before worrying about who they are specifically.</p></dd>
<dt>Attackers aren’t always afraid of being caught.</dt>
<dd>Even if you manage to track an attacker’s location and identity, the criminal system (especially internationally) may make it difficult to hold them legally accountable for their actions. This is especially true for nation-state actors working directly for a government that may be unwilling to extradite them for criminal prosecution.<a contenteditable="false" data-primary="" id="ch02.html11-eot" data-startref="ch02.html11" data-type="indexterm">&nbsp;</a><a contenteditable="false" data-primary="" id="ch02.html10-eot" data-startref="ch02.html10" data-type="indexterm">&nbsp;</a></dd>
</dl>
</section>
<section data-type="sect1" id="conclusion-id00002">
<h1>Conclusion</h1>
<p>All security attacks can be traced back to a motivated person. We’ve covered some common attacker profiles to help you identify who may want to target your services and why, allowing you to prioritize your defenses accordingly.</p>
<p>Assess who might want to target you. What are your assets? Who buys your products or services? Could your users or their actions motivate attackers? How do your defensive resources compare to the offensive resources of your potential adversaries? Even when facing a well-funded attacker, the information in the rest of this book can help make you a more expensive target, possibly removing the economic incentive for an attack. Don’t overlook the smaller, less conspicuous adversary—anonymity, location, ample time, and the difficulty of prosecution can all be advantages to an attacker, allowing them to cause you disproportionately large amounts of damage. Consider your insider risk, as all organizations face both malicious and nonmalicious potential threats from insiders. The elevated access granted to insiders allows them to inflict significant damage.</p>
<p>Stay current on the threat intelligence issued by security firms. While a multistep attack methodology can be effective, it also provides multiple contact points where you can detect and prevent an attack. Be mindful of complex attack strategies, but don’t forget that simple, unsophisticated attacks like phishing can be painfully effective. Don’t underestimate your adversaries or your own value as a target.<a contenteditable="false" data-primary="" id="ch02.html0-eot" data-startref="ch02.html0" data-type="indexterm">&nbsp;</a></p>
</section>
</section>
</body>
</html>
<div data-type="footnotes">
<p data-type="footnote" id="ch02fn1"><sup><a href="#ch02fn1-marker">1</a></sup>Stoll documented the attack in an article in <em>Communications of the ACM</em>, <a href="http://pdf.textfiles.com/academics/wilyhacker.pdf">“Stalking the Wily Hacker”</a>, and the book <em>The Cuckoo’s Egg: Tracking a Spy Through the Maze of Computer Espionage</em> (Gallery Books). Both are good resources for anyone designing secure and reliable systems, as their findings are still relevant today.</p>
<p data-type="footnote" id="ch02fn2"><sup><a href="#ch02fn2-marker">2</a></sup>As an example of how complicated this space can be, not all attackers in such conflicts are part of an organized military. For example, Dutch attackers reportedly compromised the US military during the Persian Gulf War (1991) and <a href="https://apnews.com/9bdfd653327fc9c17e643090f08d1d04">offered stolen information to the Iraqi government</a>.</p>
<p data-type="footnote" id="ch02fn3"><sup><a href="#ch02fn3-marker">3</a></sup>NSO Group’s activities have been researched and documented by The CitizenLab, a research and policy laboratory based at the Munk School of Global Affairs &amp; Public Policy, University of Toronto. For an example, see <a href="https://citizenlab.ca/2018/07/nso-spyware-targeting-amnesty-international/"><em class="hyperlink">https://citizenlab.ca/2018/07/nso-spyware-targeting-amnesty-international/</em></a>.</p>
<p data-type="footnote" id="ch02fn4"><sup><a href="#ch02fn4-marker">4</a></sup>There is some debate about who coined this term and what it means, but it became widely used after 1996 when it was adopted by <a href="http://www.hacktivismo.com/about/declaration.php">Hacktivismo</a>, a group associated with the Cult of the Dead Cow (cDc).</p>
<p data-type="footnote" id="ch02fn5"><sup><a href="#ch02fn5-marker">5</a></sup>Anonymous is a moniker that a wide variety of people use for hacktivist (and other) activities. It may (or may not) refer to a single person or a collective of related persons, depending on the situation.</p>
<p data-type="footnote" id="ch02fn6"><sup><a href="#ch02fn6-marker">6</a></sup>The race to increase the effectiveness of CAPTCHA techniques continues, with newer advancements using behavioral analysis of users as they interact with the CAPTCHA. <a href="https://www.google.com/recaptcha">reCAPTCHA</a> is a free service you can use on your website. For a relatively recent overview of the research literature, see Chow Yang-Wei, Willy Susilo, and Pairat Thorncharoensri. 2019. “CAPTCHA Design and Security Issues.” In <em>Advances in Cyber Security: Principles, Techniques, and Applications</em>, edited by Kuan-Ching Li, Xiaofeng Chen, and Willy Susilo, 69–92. Singapore: Springer.<a contenteditable="false" data-primary="" id="ch02.html5-eot" data-startref="ch02.html5" data-type="indexterm">&nbsp;</a><a contenteditable="false" data-primary="" id="ch02.html4-eot" data-startref="ch02.html4" data-type="indexterm">&nbsp;</a></p>
<p data-type="footnote" id="ch02fn7"><sup><a href="#ch02fn7-marker">7</a></sup>For an example of considering how security and privacy features are impacted by domestic partner abuse, see Matthews, Tara et al. 2017. “Stories from Survivors: Privacy &amp; Security Practices When Coping with Intimate Partner Abuse.” <em>Proceedings of the 2017 CHI Conference on Human Factors in Computing Systems</em>: 2189–2201. <a href="https://ai.google/research/pubs/pub46080"><em class="hyperlink">https://ai.google/research/pubs/pub46080</em></a>.</p>
<p data-type="footnote" id="ch02fn8"><sup><a href="#ch02fn8-marker">8</a></sup>For example, many tools are incorporating the Structure Threat Information eXpression (STIX) language to standardize the documentation of IOCs that can be traded between systems using services like the <a href="https://github.com/TAXIIProject">Trusted Automated eXchange of Indicator Information (TAXII) project</a>.</p>
<p data-type="footnote" id="ch02fn9"><sup><a href="#ch02fn9-marker">9</a></sup>Notable examples include the annual <a href="https://enterprise.verizon.com/resources/reports/dbir/">Verizon Databreach Investigations Report</a> and CrowdStrike’s annual <a href="https://www.crowdstrike.com/resources/reports/2019-crowdstrike-global-threat-report/">Global Threat Report</a>.</p>
<p data-type="footnote" id="ch02fn10"><sup><a href="#ch02fn10-marker">10</a></sup>The <a href="https://www.lockheedmartin.com/en-us/capabilities/cyber/cyber-kill-chain.html">Cyber Kill Chain</a>, conceived (and trademarked) by Lockheed Martin, is an adaptation of traditional military attack structures. It defines seven stages of cyberattacks, but we’ve found this can be adapted; some researchers simplify it to four or five key stages, as we’ve done here.</p>
<p data-type="footnote" id="ch02fn11"><sup><a href="#ch02fn11-marker">11</a></sup>Greenwald, Glenn. 2014. <em>No Place to Hide: Edward Snowden, the NSA, and the U.S. Surveillance State</em>. New York: Metropolitan Books, 149.</p>
</div>
